{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNlfl4HCT0b9"
      },
      "source": [
        "#Install Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_z5GuCGNKPxK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "feb2d301-a9f3-4064-fc3b-7aecf6fa7163"
      },
      "source": [
        "!pip install -U spacy\n",
        "!pip install scispacy\n",
        "!pip install -q https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.1/en_core_sci_lg-0.5.1.tar.gz\n",
        "\n",
        "# NER models\n",
        "!pip install -q https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.1/en_ner_bc5cdr_md-0.5.1.tar.gz\n",
        "!pip install -q https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.1/en_ner_jnlpba_md-0.5.1.tar.gz\n",
        "!pip install -q https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.1/en_ner_bionlp13cg_md-0.5.1.tar.gz\n",
        "!pip install -q https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.1/en_ner_craft_md-0.5.1.tar.gz"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.4.4)\n",
            "Collecting spacy\n",
            "  Using cached spacy-3.8.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (27 kB)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.10)\n",
            "Collecting thinc<8.4.0,>=8.3.4 (from spacy)\n",
            "  Using cached thinc-8.3.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.10.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.7.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.26.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.10.22)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.6.15)\n",
            "Collecting blis<1.4.0,>=1.3.0 (from thinc<8.4.0,>=8.3.4->spacy)\n",
            "  Using cached blis-1.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Collecting numpy>=1.19.0 (from spacy)\n",
            "  Using cached numpy-2.3.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
            "Collecting pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 (from spacy)\n",
            "  Using cached pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.1)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.2.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (6.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Using cached spacy-3.8.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.0 MB)\n",
            "Using cached thinc-8.3.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "Using cached numpy-2.3.1-cp311-cp311-manylinux_2_28_x86_64.whl (16.9 MB)\n",
            "Using cached pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
            "Using cached blis-1.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\n",
            "Installing collected packages: numpy, pydantic, blis, thinc, spacy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 1.10.22\n",
            "    Uninstalling pydantic-1.10.22:\n",
            "      Successfully uninstalled pydantic-1.10.22\n",
            "  Attempting uninstall: blis\n",
            "    Found existing installation: blis 0.7.11\n",
            "    Uninstalling blis-0.7.11:\n",
            "      Successfully uninstalled blis-0.7.11\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 8.1.12\n",
            "    Uninstalling thinc-8.1.12:\n",
            "      Successfully uninstalled thinc-8.1.12\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 3.4.4\n",
            "    Uninstalling spacy-3.4.4:\n",
            "      Successfully uninstalled spacy-3.4.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "en-core-sci-lg 0.5.1 requires spacy<3.5.0,>=3.4.1, but you have spacy 3.8.7 which is incompatible.\n",
            "en-ner-bc5cdr-md 0.5.1 requires spacy<3.5.0,>=3.4.1, but you have spacy 3.8.7 which is incompatible.\n",
            "en-ner-craft-md 0.5.1 requires spacy<3.5.0,>=3.4.1, but you have spacy 3.8.7 which is incompatible.\n",
            "en-ner-bionlp13cg-md 0.5.1 requires spacy<3.5.0,>=3.4.1, but you have spacy 3.8.7 which is incompatible.\n",
            "en-ner-jnlpba-md 0.5.1 requires spacy<3.5.0,>=3.4.1, but you have spacy 3.8.7 which is incompatible.\n",
            "scispacy 0.5.5 requires spacy<3.8.0,>=3.7.0, but you have spacy 3.8.7 which is incompatible.\n",
            "cupy-cuda12x 13.3.0 requires numpy<2.3,>=1.22, but you have numpy 2.3.1 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.1 which is incompatible.\n",
            "gradio 5.31.0 requires typer<1.0,>=0.12; sys_platform != \"emscripten\", but you have typer 0.7.0 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.3.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed blis-1.3.0 numpy-2.3.1 pydantic-2.11.7 spacy-3.8.7 thinc-8.3.6\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "blis",
                  "numpy",
                  "pydantic",
                  "spacy",
                  "thinc"
                ]
              },
              "id": "923ae9c6c85144859f3a048ea911fd71"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scispacy in /usr/local/lib/python3.11/dist-packages (0.5.5)\n",
            "Collecting spacy<3.8.0,>=3.7.0 (from scispacy)\n",
            "  Using cached spacy-3.7.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (27 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from scispacy) (1.15.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scispacy) (2.32.3)\n",
            "Requirement already satisfied: conllu in /usr/local/lib/python3.11/dist-packages (from scispacy) (6.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from scispacy) (2.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from scispacy) (1.5.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.3 in /usr/local/lib/python3.11/dist-packages (from scispacy) (1.6.1)\n",
            "Requirement already satisfied: pysbd in /usr/local/lib/python3.11/dist-packages (from scispacy) (0.3.4)\n",
            "Requirement already satisfied: nmslib-metabrainz==2.1.3 in /usr/local/lib/python3.11/dist-packages (from scispacy) (2.1.3)\n",
            "Requirement already satisfied: pybind11>=2.2.3 in /usr/local/lib/python3.11/dist-packages (from nmslib-metabrainz==2.1.3->scispacy) (2.13.6)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from nmslib-metabrainz==2.1.3->scispacy) (5.9.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->scispacy) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->scispacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->scispacy) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->scispacy) (2025.6.15)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.20.3->scispacy) (3.6.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->scispacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->scispacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->scispacy) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->scispacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->scispacy) (3.0.10)\n",
            "Collecting thinc<8.3.0,>=8.2.2 (from spacy<3.8.0,>=3.7.0->scispacy)\n",
            "  Using cached thinc-8.2.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->scispacy) (0.10.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->scispacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->scispacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->scispacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->scispacy) (0.7.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->scispacy) (4.67.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->scispacy) (2.11.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->scispacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->scispacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->scispacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->scispacy) (3.5.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->scispacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->scispacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->scispacy) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->scispacy) (4.14.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->scispacy) (0.4.1)\n",
            "Collecting blis<0.8.0,>=0.7.8 (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->scispacy)\n",
            "  Using cached blis-0.7.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->scispacy) (0.1.5)\n",
            "Collecting numpy (from scispacy)\n",
            "  Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->scispacy) (8.2.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->scispacy) (0.21.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->scispacy) (6.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->scispacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->scispacy) (1.2.1)\n",
            "Using cached spacy-3.7.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.6 MB)\n",
            "Using cached thinc-8.2.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (920 kB)\n",
            "Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "Using cached blis-0.7.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.2 MB)\n",
            "Installing collected packages: numpy, blis, thinc, spacy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.3.1\n",
            "    Uninstalling numpy-2.3.1:\n",
            "      Successfully uninstalled numpy-2.3.1\n",
            "  Attempting uninstall: blis\n",
            "    Found existing installation: blis 1.3.0\n",
            "    Uninstalling blis-1.3.0:\n",
            "      Successfully uninstalled blis-1.3.0\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 8.3.6\n",
            "    Uninstalling thinc-8.3.6:\n",
            "      Successfully uninstalled thinc-8.3.6\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 3.8.7\n",
            "    Uninstalling spacy-3.8.7:\n",
            "      Successfully uninstalled spacy-3.8.7\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "en-core-sci-lg 0.5.1 requires spacy<3.5.0,>=3.4.1, but you have spacy 3.7.5 which is incompatible.\n",
            "en-ner-bc5cdr-md 0.5.1 requires spacy<3.5.0,>=3.4.1, but you have spacy 3.7.5 which is incompatible.\n",
            "en-ner-craft-md 0.5.1 requires spacy<3.5.0,>=3.4.1, but you have spacy 3.7.5 which is incompatible.\n",
            "en-ner-bionlp13cg-md 0.5.1 requires spacy<3.5.0,>=3.4.1, but you have spacy 3.7.5 which is incompatible.\n",
            "en-ner-jnlpba-md 0.5.1 requires spacy<3.5.0,>=3.4.1, but you have spacy 3.7.5 which is incompatible.\n",
            "gradio 5.31.0 requires typer<1.0,>=0.12; sys_platform != \"emscripten\", but you have typer 0.7.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed blis-0.7.11 numpy-1.26.4 spacy-3.7.5 thinc-8.2.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "blis",
                  "numpy",
                  "spacy",
                  "thinc"
                ]
              },
              "id": "0866f0662a9c46c48d3775125c529d25"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "scispacy 0.5.5 requires spacy<3.8.0,>=3.7.0, but you have spacy 3.4.4 which is incompatible.\n",
            "albumentations 2.0.8 requires pydantic>=2.9.2, but you have pydantic 1.10.22 which is incompatible.\n",
            "google-genai 1.23.0 requires pydantic<3.0.0,>=2.0.0, but you have pydantic 1.10.22 which is incompatible.\n",
            "langchain-core 0.3.67 requires pydantic>=2.7.4, but you have pydantic 1.10.22 which is incompatible.\n",
            "langchain 0.3.26 requires pydantic<3.0.0,>=2.7.4, but you have pydantic 1.10.22 which is incompatible.\n",
            "gradio 5.31.0 requires pydantic<2.12,>=2.0, but you have pydantic 1.10.22 which is incompatible.\n",
            "gradio 5.31.0 requires typer<1.0,>=0.12; sys_platform != \"emscripten\", but you have typer 0.7.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLey8-aVT57b"
      },
      "source": [
        "#Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fkHBVMO_yUh"
      },
      "source": [
        "import scispacy\n",
        "import spacy\n",
        "\n",
        "#Core models\n",
        "import en_core_sci_lg\n",
        "\n",
        "#NER specific models\n",
        "import en_ner_craft_md\n",
        "import en_ner_bc5cdr_md\n",
        "import en_ner_jnlpba_md\n",
        "import en_ner_bionlp13cg_md\n",
        "\n",
        "#Tools for extracting & displaying data\n",
        "from spacy import displacy\n",
        "import pandas as pd\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZb1doG8UFGT"
      },
      "source": [
        "# Compare Different Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GDRSV_bEY9Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5047d06e-1f01-4c07-fdda-a120d2f220a5"
      },
      "source": [
        "import spacy\n",
        "import json\n",
        "from collections import defaultdict, Counter\n",
        "import pandas as pd\n",
        "from typing import Dict, List, Any, Set, Optional, Tuple\n",
        "import logging\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "from sklearn.metrics import precision_recall_fscore_support, classification_report\n",
        "\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class ScispaCyNERAnalyzer:\n",
        "    def __init__(self, min_entity_length: int = 2):\n",
        "        \"\"\"\n",
        "        Initialize the analyzer\n",
        "\n",
        "        Args:\n",
        "            min_entity_length: Minimum character length for entities to be considered\n",
        "        \"\"\"\n",
        "        self.min_entity_length = min_entity_length\n",
        "        self.medical_relevant_labels = {\n",
        "            # Disease and condition labels\n",
        "            'DISEASE', 'DISORDER', 'CONDITION', 'PATHOLOGICAL_FORMATION',\n",
        "            'SYMPTOM', 'SIGN', 'SYNDROME', 'CANCER', 'PHENOTYPE',\n",
        "            'INJURY_OR_POISONING', 'PATHOLOGIC_FUNCTION',\n",
        "\n",
        "            # Chemical and drug labels\n",
        "            'CHEMICAL', 'DRUG', 'MEDICATION', 'SIMPLE_CHEMICAL',\n",
        "            'AMINO_ACID', 'CARBOHYDRATE', 'LIPID', 'PHARMACOLOGIC_SUBSTANCE',\n",
        "            'VITAMIN', 'HORMONE', 'ENZYME', 'NUCLEIC_ACID',\n",
        "\n",
        "            # Biological and genetic labels\n",
        "            'GENE', 'PROTEIN', 'GENE_OR_GENE_PRODUCT', 'CELL',\n",
        "            'CELL_TYPE', 'CELL_LINE', 'VIRUS', 'BACTERIUM',\n",
        "            'ORGANISM', 'ORGANISM_SUBSTANCE', 'ORGANISM_ATTRIBUTE',\n",
        "\n",
        "            # Anatomical labels\n",
        "            'ANATOMY', 'BODY_PART', 'ORGAN', 'TISSUE', 'BODY_SUBSTANCE',\n",
        "            'BODY_LOCATION_OR_REGION', 'MULTI_TISSUE_STRUCTURE',\n",
        "            'DEVELOPING_ANATOMICAL_STRUCTURE', 'ANATOMICAL_STRUCTURE',\n",
        "\n",
        "            # Medical procedure and diagnostic labels\n",
        "            'DIAGNOSTIC_PROCEDURE', 'THERAPEUTIC_PROCEDURE', 'PROCEDURE',\n",
        "            'LABORATORY_PROCEDURE', 'MEDICAL_DEVICE', 'RESEARCH_ACTIVITY',\n",
        "\n",
        "            # Other medical labels\n",
        "            'CLINICAL_ATTRIBUTE', 'MEDICAL_FINDING', 'LABORATORY_OR_TEST_RESULT',\n",
        "            'FOOD', 'ENVIRONMENTAL_EXPOSURE', 'BEHAVIOR',\n",
        "\n",
        "            # CHEBI ontology for chemicals\n",
        "            'CHEBI', 'CHEBI_ROLE', 'CHEBI_DRUG',\n",
        "\n",
        "            # GO ontology labels\n",
        "            'GO_BP', 'GO_CC', 'GO_MF',  # Biological Process, Cellular Component, Molecular Function\n",
        "\n",
        "            # Other ontology labels\n",
        "            'SO', 'PR', 'UBERON', 'CL', 'MOP', 'NCBITaxon'\n",
        "        }\n",
        "\n",
        "        # Labels to exclude (non-medical or too generic)\n",
        "        self.noise_labels = {\n",
        "            'ENTITY', 'PERSON', 'LOCATION', 'ORGANIZATION', 'DATE', 'TIME',\n",
        "            'PERCENT', 'MONEY', 'QUANTITY', 'ORDINAL', 'CARDINAL',\n",
        "            'GPE', 'LOC', 'FAC', 'EVENT', 'LANGUAGE', 'LAW', 'NORP',\n",
        "            'WORK_OF_ART', 'PRODUCT'\n",
        "        }\n",
        "\n",
        "        # Common English stop words to filter out\n",
        "        self.stop_words = {\n",
        "            'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves',\n",
        "            'you', 'your', 'yours', 'yourself', 'yourselves', 'he', 'him',\n",
        "            'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its',\n",
        "            'itself', 'they', 'them', 'their', 'theirs', 'themselves',\n",
        "            'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those',\n",
        "            'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being',\n",
        "            'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing',\n",
        "            'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as',\n",
        "            'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about',\n",
        "            'against', 'between', 'into', 'through', 'during', 'before',\n",
        "            'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in',\n",
        "            'out', 'on', 'off', 'over', 'under', 'again', 'further',\n",
        "            'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how',\n",
        "            'all', 'both', 'each', 'few', 'more', 'most', 'other', 'some',\n",
        "            'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so',\n",
        "            'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don',\n",
        "            'should', 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain',\n",
        "            'aren', 'couldn', 'didn', 'doesn', 'hadn', 'hasn', 'haven',\n",
        "            'isn', 'ma', 'mightn', 'mustn', 'needn', 'shan', 'shouldn',\n",
        "            'wasn', 'weren', 'won', 'wouldn'\n",
        "        }\n",
        "\n",
        "        self.available_models = self._discover_models()\n",
        "        self.results = {}\n",
        "        self.evaluation_results = {}\n",
        "\n",
        "    def _discover_models(self) -> List[str]:\n",
        "        potential_models = [\n",
        "            \"en_core_sci_lg\",\n",
        "            \"en_core_sci_scibert\",\n",
        "            \"en_ner_bc5cdr_md\",\n",
        "            \"en_ner_jnlpba_md\",\n",
        "            \"en_ner_bionlp13cg_md\",\n",
        "            \"en_ner_craft_md\"\n",
        "        ]\n",
        "\n",
        "        available = []\n",
        "        for model in potential_models:\n",
        "            try:\n",
        "                spacy.load(model)\n",
        "                available.append(model)\n",
        "                logger.info(f\"✓ Found model: {model}\")\n",
        "            except:\n",
        "                logger.warning(f\"✗ Model not available: {model}\")\n",
        "\n",
        "        return available\n",
        "\n",
        "    def _is_medical_entity(self, text: str, label: str) -> bool:\n",
        "        if label in self.medical_relevant_labels:\n",
        "            return True\n",
        "\n",
        "        if label in self.noise_labels:\n",
        "            return False\n",
        "\n",
        "        if text.lower() in self.stop_words:\n",
        "            return False\n",
        "\n",
        "        return False\n",
        "\n",
        "    def analyze_text(self, text: str, models: Optional[List[str]] = None) -> Dict[str, Any]:\n",
        "        if models is None:\n",
        "            models = self.available_models\n",
        "\n",
        "        self.results = {\n",
        "            \"input_text\": text,\n",
        "            \"text_length\": len(text),\n",
        "            \"analysis_timestamp\": datetime.now().isoformat(),\n",
        "            \"models\": {}\n",
        "        }\n",
        "\n",
        "        for model_name in models:\n",
        "            logger.info(f\"Processing with {model_name}...\")\n",
        "            try:\n",
        "                nlp = spacy.load(model_name)\n",
        "                doc = nlp(text)\n",
        "\n",
        "                entities = []\n",
        "                medical_entities = []\n",
        "\n",
        "                for ent in doc.ents:\n",
        "                    if len(ent.text) >= self.min_entity_length:\n",
        "                        entity_data = {\n",
        "                            \"text\": ent.text,\n",
        "                            \"label\": ent.label_,\n",
        "                            \"start\": ent.start_char,\n",
        "                            \"end\": ent.end_char,\n",
        "                            \"confidence\": getattr(ent, 'kb_id_', 1.0)\n",
        "                        }\n",
        "                        entities.append(entity_data)\n",
        "\n",
        "                        if self._is_medical_entity(ent.text, ent.label_):\n",
        "                            medical_entities.append(entity_data)\n",
        "\n",
        "                all_labels = Counter(e[\"label\"] for e in entities)\n",
        "                medical_labels = Counter(e[\"label\"] for e in medical_entities)\n",
        "\n",
        "                self.results[\"models\"][model_name] = {\n",
        "                    \"entities\": entities,\n",
        "                    \"medical_entities\": medical_entities,\n",
        "                    \"entity_count\": len(entities),\n",
        "                    \"medical_entity_count\": len(medical_entities),\n",
        "                    \"unique_entities\": len(set(e[\"text\"] for e in entities)),\n",
        "                    \"unique_medical_entities\": len(set(e[\"text\"] for e in medical_entities)),\n",
        "                    \"label_distribution\": dict(all_labels),\n",
        "                    \"medical_label_distribution\": dict(medical_labels),\n",
        "                    \"processing_time\": getattr(doc, 'user_data', {}).get('processing_time', None)\n",
        "                }\n",
        "\n",
        "            except Exception as e:\n",
        "                logger.error(f\"Error processing {model_name}: {str(e)}\")\n",
        "                self.results[\"models\"][model_name] = {\"error\": str(e)}\n",
        "\n",
        "        return self.results\n",
        "\n",
        "    def evaluate_models(self,\n",
        "                       sample_texts: List[str],\n",
        "                       expected_entities: List[List[str]],\n",
        "                       models: Optional[List[str]] = None,\n",
        "                       case_sensitive: bool = False,\n",
        "                       partial_match: bool = False) -> Dict[str, Any]:\n",
        "\n",
        "        if models is None:\n",
        "            models = self.available_models\n",
        "\n",
        "        self.evaluation_results = {\n",
        "            \"evaluation_timestamp\": datetime.now().isoformat(),\n",
        "            \"num_samples\": len(sample_texts),\n",
        "            \"case_sensitive\": case_sensitive,\n",
        "            \"partial_match\": partial_match,\n",
        "            \"models\": {}\n",
        "        }\n",
        "\n",
        "        for model_name in models:\n",
        "            logger.info(f\"Evaluating {model_name}...\")\n",
        "\n",
        "            try:\n",
        "                nlp = spacy.load(model_name)\n",
        "\n",
        "                all_true_positives = 0\n",
        "                all_false_positives = 0\n",
        "                all_false_negatives = 0\n",
        "                sample_results = []\n",
        "                for idx, (text, expected) in enumerate(zip(sample_texts, expected_entities)):\n",
        "                    doc = nlp(text)\n",
        "\n",
        "                    predicted = []\n",
        "                    for ent in doc.ents:\n",
        "                        if len(ent.text) >= self.min_entity_length:\n",
        "                            if self._is_medical_entity(ent.text, ent.label_):\n",
        "                                predicted.append(ent.text)\n",
        "\n",
        "                    if not case_sensitive:\n",
        "                        predicted_normalized = [p.lower() for p in predicted]\n",
        "                        expected_normalized = [e.lower() for e in expected]\n",
        "                    else:\n",
        "                        predicted_normalized = predicted\n",
        "                        expected_normalized = expected\n",
        "\n",
        "                    if partial_match:\n",
        "                        tp, fp, fn = self._calculate_partial_match_metrics(\n",
        "                            predicted_normalized, expected_normalized\n",
        "                        )\n",
        "                    else:\n",
        "                        tp, fp, fn = self._calculate_exact_match_metrics(\n",
        "                            predicted_normalized, expected_normalized\n",
        "                        )\n",
        "\n",
        "                    all_true_positives += tp\n",
        "                    all_false_positives += fp\n",
        "                    all_false_negatives += fn\n",
        "\n",
        "                    sample_results.append({\n",
        "                        \"sample_idx\": idx,\n",
        "                        \"text_preview\": text[:100] + \"...\" if len(text) > 100 else text,\n",
        "                        \"expected\": expected,\n",
        "                        \"predicted\": predicted,\n",
        "                        \"true_positives\": tp,\n",
        "                        \"false_positives\": fp,\n",
        "                        \"false_negatives\": fn,\n",
        "                        \"precision\": tp / (tp + fp) if (tp + fp) > 0 else 0,\n",
        "                        \"recall\": tp / (tp + fn) if (tp + fn) > 0 else 0,\n",
        "                        \"f1\": 2 * tp / (2 * tp + fp + fn) if (2 * tp + fp + fn) > 0 else 0\n",
        "                    })\n",
        "\n",
        "                precision = all_true_positives / (all_true_positives + all_false_positives) \\\n",
        "                    if (all_true_positives + all_false_positives) > 0 else 0\n",
        "                recall = all_true_positives / (all_true_positives + all_false_negatives) \\\n",
        "                    if (all_true_positives + all_false_negatives) > 0 else 0\n",
        "                f1 = 2 * (precision * recall) / (precision + recall) \\\n",
        "                    if (precision + recall) > 0 else 0\n",
        "\n",
        "                self.evaluation_results[\"models\"][model_name] = {\n",
        "                    \"overall_metrics\": {\n",
        "                        \"precision\": precision,\n",
        "                        \"recall\": recall,\n",
        "                        \"f1_score\": f1,\n",
        "                        \"true_positives\": all_true_positives,\n",
        "                        \"false_positives\": all_false_positives,\n",
        "                        \"false_negatives\": all_false_negatives\n",
        "                    },\n",
        "                    \"sample_results\": sample_results,\n",
        "                    \"avg_precision\": np.mean([s[\"precision\"] for s in sample_results]),\n",
        "                    \"avg_recall\": np.mean([s[\"recall\"] for s in sample_results]),\n",
        "                    \"avg_f1\": np.mean([s[\"f1\"] for s in sample_results])\n",
        "                }\n",
        "\n",
        "            except Exception as e:\n",
        "                logger.error(f\"Error evaluating {model_name}: {str(e)}\")\n",
        "                self.evaluation_results[\"models\"][model_name] = {\"error\": str(e)}\n",
        "\n",
        "        return self.evaluation_results\n",
        "\n",
        "    def _calculate_exact_match_metrics(self, predicted: List[str], expected: List[str]) -> Tuple[int, int, int]:\n",
        "        predicted_set = set(predicted)\n",
        "        expected_set = set(expected)\n",
        "\n",
        "        true_positives = len(predicted_set & expected_set)\n",
        "        false_positives = len(predicted_set - expected_set)\n",
        "        false_negatives = len(expected_set - predicted_set)\n",
        "\n",
        "        return true_positives, false_positives, false_negatives\n",
        "\n",
        "    def _calculate_partial_match_metrics(self, predicted: List[str], expected: List[str]) -> Tuple[int, int, int]:\n",
        "        true_positives = 0\n",
        "        matched_expected = set()\n",
        "        matched_predicted = set()\n",
        "\n",
        "        for i, pred in enumerate(predicted):\n",
        "            for j, exp in enumerate(expected):\n",
        "                if j not in matched_expected and i not in matched_predicted:\n",
        "                    if pred in exp or exp in pred:\n",
        "                        true_positives += 1\n",
        "                        matched_expected.add(j)\n",
        "                        matched_predicted.add(i)\n",
        "                        break\n",
        "\n",
        "        false_positives = len(predicted) - len(matched_predicted)\n",
        "        false_negatives = len(expected) - len(matched_expected)\n",
        "\n",
        "        return true_positives, false_positives, false_negatives\n",
        "\n",
        "    def generate_evaluation_report(self) -> str:\n",
        "        report = []\n",
        "        report.append(\"=\" * 80)\n",
        "        report.append(\"SCISPACY MODEL EVALUATION REPORT\")\n",
        "        report.append(\"=\" * 80)\n",
        "        report.append(f\"\\nEvaluation Date: {self.evaluation_results['evaluation_timestamp']}\")\n",
        "        report.append(f\"Number of Samples: {self.evaluation_results['num_samples']}\")\n",
        "        report.append(f\"Case Sensitive: {self.evaluation_results['case_sensitive']}\")\n",
        "        report.append(f\"Partial Match: {self.evaluation_results['partial_match']}\")\n",
        "\n",
        "        report.append(\"\\n\" + \"-\" * 80)\n",
        "        report.append(\"MODEL PERFORMANCE SUMMARY\")\n",
        "        report.append(\"-\" * 80)\n",
        "\n",
        "        model_summary = []\n",
        "        for model_name, results in self.evaluation_results['models'].items():\n",
        "            if \"error\" in results:\n",
        "                model_summary.append({\n",
        "                    \"Model\": model_name,\n",
        "                    \"Status\": \"Error\",\n",
        "                    \"Precision\": \"N/A\",\n",
        "                    \"Recall\": \"N/A\",\n",
        "                    \"F1-Score\": \"N/A\"\n",
        "                })\n",
        "            else:\n",
        "                metrics = results[\"overall_metrics\"]\n",
        "                model_summary.append({\n",
        "                    \"Model\": model_name,\n",
        "                    \"Status\": \"Success\",\n",
        "                    \"Precision\": f\"{metrics['precision']:.3f}\",\n",
        "                    \"Recall\": f\"{metrics['recall']:.3f}\",\n",
        "                    \"F1-Score\": f\"{metrics['f1_score']:.3f}\"\n",
        "                })\n",
        "\n",
        "        df = pd.DataFrame(model_summary)\n",
        "        report.append(\"\\n\" + df.to_string(index=False))\n",
        "\n",
        "        report.append(\"\\n\" + \"=\" * 80)\n",
        "        report.append(\"DETAILED MODEL EVALUATION\")\n",
        "        report.append(\"=\" * 80)\n",
        "\n",
        "        for model_name, results in self.evaluation_results['models'].items():\n",
        "            report.append(f\"\\n\\n{'='*60}\")\n",
        "            report.append(f\"Model: {model_name}\")\n",
        "            report.append(f\"{'='*60}\")\n",
        "\n",
        "            if \"error\" in results:\n",
        "                report.append(f\"Error: {results['error']}\")\n",
        "                continue\n",
        "\n",
        "            metrics = results[\"overall_metrics\"]\n",
        "            report.append(f\"\\nOverall Performance:\")\n",
        "            report.append(f\"  Precision: {metrics['precision']:.3f}\")\n",
        "            report.append(f\"  Recall: {metrics['recall']:.3f}\")\n",
        "            report.append(f\"  F1-Score: {metrics['f1_score']:.3f}\")\n",
        "            report.append(f\"  True Positives: {metrics['true_positives']}\")\n",
        "            report.append(f\"  False Positives: {metrics['false_positives']}\")\n",
        "            report.append(f\"  False Negatives: {metrics['false_negatives']}\")\n",
        "\n",
        "            report.append(f\"\\nAverage Sample Performance:\")\n",
        "            report.append(f\"  Avg Precision: {results['avg_precision']:.3f}\")\n",
        "            report.append(f\"  Avg Recall: {results['avg_recall']:.3f}\")\n",
        "            report.append(f\"  Avg F1-Score: {results['avg_f1']:.3f}\")\n",
        "\n",
        "            report.append(f\"\\nSample-Level Results (first 5):\")\n",
        "            for sample in results[\"sample_results\"][:5]:\n",
        "                report.append(f\"\\n  Sample {sample['sample_idx']}:\")\n",
        "                report.append(f\"    Text: {sample['text_preview']}\")\n",
        "                report.append(f\"    Expected: {', '.join(sample['expected'][:5])}\")\n",
        "                if len(sample['expected']) > 5:\n",
        "                    report.append(f\"              ... and {len(sample['expected']) - 5} more\")\n",
        "                report.append(f\"    Predicted: {', '.join(sample['predicted'][:5])}\")\n",
        "                if len(sample['predicted']) > 5:\n",
        "                    report.append(f\"               ... and {len(sample['predicted']) - 5} more\")\n",
        "                report.append(f\"    Metrics: P={sample['precision']:.3f}, R={sample['recall']:.3f}, F1={sample['f1']:.3f}\")\n",
        "\n",
        "        report.append(\"\\n\" + \"=\" * 80)\n",
        "        report.append(\"BEST PERFORMING MODEL\")\n",
        "        report.append(\"=\" * 80)\n",
        "\n",
        "        best_model = None\n",
        "        best_f1 = 0\n",
        "        for model_name, results in self.evaluation_results['models'].items():\n",
        "            if \"error\" not in results:\n",
        "                f1 = results[\"overall_metrics\"][\"f1_score\"]\n",
        "                if f1 > best_f1:\n",
        "                    best_f1 = f1\n",
        "                    best_model = model_name\n",
        "\n",
        "        if best_model:\n",
        "            report.append(f\"\\nBest Model: {best_model}\")\n",
        "            report.append(f\"F1-Score: {best_f1:.3f}\")\n",
        "\n",
        "        return \"\\n\".join(report)\n",
        "\n",
        "    def export_evaluation_results(self, filename: str = \"scispacy_evaluation_results.json\"):\n",
        "        with open(filename, 'w') as f:\n",
        "            json.dump(self.evaluation_results, f, indent=2)\n",
        "        logger.info(f\"Evaluation results exported to {filename}\")\n",
        "\n",
        "    def get_error_analysis(self) -> pd.DataFrame:\n",
        "        if not self.evaluation_results:\n",
        "            return pd.DataFrame()\n",
        "\n",
        "        error_data = []\n",
        "\n",
        "        for model_name, results in self.evaluation_results['models'].items():\n",
        "            if \"error\" not in results and \"sample_results\" in results:\n",
        "                false_positives = []\n",
        "                false_negatives = []\n",
        "\n",
        "                for sample in results[\"sample_results\"]:\n",
        "                    predicted_set = set(sample[\"predicted\"])\n",
        "                    expected_set = set(sample[\"expected\"])\n",
        "\n",
        "                    fps = predicted_set - expected_set\n",
        "                    fns = expected_set - predicted_set\n",
        "\n",
        "                    false_positives.extend(fps)\n",
        "                    false_negatives.extend(fns)\n",
        "\n",
        "                fp_counts = Counter(false_positives)\n",
        "                fn_counts = Counter(false_negatives)\n",
        "\n",
        "                for entity, count in fp_counts.most_common(10):\n",
        "                    error_data.append({\n",
        "                        \"Model\": model_name,\n",
        "                        \"Error Type\": \"False Positive\",\n",
        "                        \"Entity\": entity,\n",
        "                        \"Count\": count\n",
        "                    })\n",
        "\n",
        "                for entity, count in fn_counts.most_common(10):\n",
        "                    error_data.append({\n",
        "                        \"Model\": model_name,\n",
        "                        \"Error Type\": \"False Negative\",\n",
        "                        \"Entity\": entity,\n",
        "                        \"Count\": count\n",
        "                    })\n",
        "\n",
        "        return pd.DataFrame(error_data)\n",
        "\n",
        "    def generate_report(self, medical_only: bool = True) -> str:\n",
        "\n",
        "        if not self.results:\n",
        "            return \"No analysis results available. Run analyze_text() first.\"\n",
        "\n",
        "        report = []\n",
        "        report.append(\"=\" * 80)\n",
        "        report.append(\"SCISPACY NER ANALYSIS REPORT - MEDICAL ENTITIES\")\n",
        "        report.append(\"=\" * 80)\n",
        "        report.append(f\"\\nAnalysis Date: {self.results['analysis_timestamp']}\")\n",
        "        report.append(f\"Text Length: {self.results['text_length']} characters\")\n",
        "        report.append(f\"Models Analyzed: {len(self.results['models'])}\")\n",
        "\n",
        "        entity_key = 'medical_entity_count' if medical_only else 'entity_count'\n",
        "        total_entities = sum(m.get(entity_key, 0) for m in self.results['models'].values())\n",
        "        report.append(f\"\\nTotal Medical Entities Found: {total_entities}\")\n",
        "\n",
        "        report.append(\"\\n\" + \"-\" * 80)\n",
        "        report.append(\"MODEL PERFORMANCE SUMMARY\")\n",
        "        report.append(\"-\" * 80)\n",
        "\n",
        "        model_stats = []\n",
        "        for model_name, data in self.results['models'].items():\n",
        "            if \"error\" in data:\n",
        "                model_stats.append({\n",
        "                    \"Model\": model_name,\n",
        "                    \"Status\": \"Error\",\n",
        "                    \"Total Entities\": 0,\n",
        "                    \"Medical Entities\": 0,\n",
        "                    \"Medical %\": \"0%\"\n",
        "                })\n",
        "            else:\n",
        "                total = data['entity_count']\n",
        "                medical = data['medical_entity_count']\n",
        "                percentage = (medical / total * 100) if total > 0 else 0\n",
        "\n",
        "                model_stats.append({\n",
        "                    \"Model\": model_name,\n",
        "                    \"Status\": \"Success\",\n",
        "                    \"Total Entities\": total,\n",
        "                    \"Medical Entities\": medical,\n",
        "                    \"Medical %\": f\"{percentage:.1f}%\"\n",
        "                })\n",
        "\n",
        "        df = pd.DataFrame(model_stats)\n",
        "        report.append(\"\\n\" + df.to_string(index=False))\n",
        "\n",
        "        report.append(\"\\n\" + \"=\" * 80)\n",
        "        report.append(\"DETAILED MODEL ANALYSIS\")\n",
        "        report.append(\"=\" * 80)\n",
        "\n",
        "        for model_name, data in self.results['models'].items():\n",
        "            report.append(f\"\\n\\n{'='*60}\")\n",
        "            report.append(f\"Model: {model_name}\")\n",
        "            report.append(f\"{'='*60}\")\n",
        "\n",
        "            if \"error\" in data:\n",
        "                report.append(f\"Error: {data['error']}\")\n",
        "                continue\n",
        "\n",
        "            report.append(f\"Total Entities: {data['entity_count']}\")\n",
        "            report.append(f\"Medical Entities: {data['medical_entity_count']}\")\n",
        "            report.append(f\"Unique Medical Entities: {data['unique_medical_entities']}\")\n",
        "\n",
        "            if data['medical_label_distribution']:\n",
        "                report.append(\"\\nMedical Label Distribution:\")\n",
        "                for label, count in sorted(data['medical_label_distribution'].items(),\n",
        "                                          key=lambda x: x[1], reverse=True):\n",
        "                    report.append(f\"  - {label}: {count}\")\n",
        "\n",
        "            entities_to_show = data['medical_entities'] if medical_only else data['entities']\n",
        "            if entities_to_show:\n",
        "                report.append(f\"\\nSample Medical Entities (first 10):\")\n",
        "                for i, ent in enumerate(entities_to_show[:10]):\n",
        "                    report.append(f\"  {i+1}. '{ent['text']}' ({ent['label']})\")\n",
        "\n",
        "        # Cross-model medical entity comparison\n",
        "        report.append(\"\\n\" + \"=\" * 80)\n",
        "        report.append(\"CROSS-MODEL MEDICAL ENTITY COMPARISON\")\n",
        "        report.append(\"=\" * 80)\n",
        "\n",
        "        medical_entities = defaultdict(lambda: {\"models\": set(), \"labels\": set()})\n",
        "\n",
        "        for model_name, data in self.results['models'].items():\n",
        "            if \"medical_entities\" in data:\n",
        "                for ent in data['medical_entities']:\n",
        "                    key = ent['text'].lower()\n",
        "                    medical_entities[key][\"models\"].add(model_name)\n",
        "                    medical_entities[key][\"labels\"].add(ent['label'])\n",
        "\n",
        "        # Consensus medical entities\n",
        "        consensus_entities = {\n",
        "            text: info for text, info in medical_entities.items()\n",
        "            if len(info[\"models\"]) > 1\n",
        "        }\n",
        "\n",
        "        if consensus_entities:\n",
        "            report.append(f\"\\nMedical entities found by multiple models ({len(consensus_entities)}):\")\n",
        "            sorted_consensus = sorted(\n",
        "                consensus_entities.items(),\n",
        "                key=lambda x: len(x[1][\"models\"]),\n",
        "                reverse=True\n",
        "            )\n",
        "\n",
        "            for text, info in sorted_consensus[:15]:\n",
        "                labels = ', '.join(sorted(info[\"labels\"]))\n",
        "                report.append(f\"  - '{text}': {len(info['models'])} models\")\n",
        "                report.append(f\"    Labels: {labels}\")\n",
        "\n",
        "        return \"\\n\".join(report)\n",
        "\n",
        "    def generate_pubmed_query(self,\n",
        "                            max_terms: int = 5,\n",
        "                            min_model_agreement: int = 2,\n",
        "                            use_medical_only: bool = True) -> str:\n",
        "        entity_metadata = defaultdict(lambda: {\n",
        "            \"count\": 0,\n",
        "            \"labels\": set(),\n",
        "            \"models\": set()\n",
        "        })\n",
        "\n",
        "        for model_name, model_data in self.results['models'].items():\n",
        "            entities_key = 'medical_entities' if use_medical_only else 'entities'\n",
        "            if entities_key in model_data:\n",
        "                for ent in model_data[entities_key]:\n",
        "                    key = ent['text'].lower()\n",
        "                    entity_metadata[key][\"count\"] += 1\n",
        "                    entity_metadata[key][\"labels\"].add(ent['label'])\n",
        "                    entity_metadata[key][\"models\"].add(model_name)\n",
        "\n",
        "        ranked_entities = []\n",
        "\n",
        "        for text, metadata in entity_metadata.items():\n",
        "            # Skip if not enough model agreement\n",
        "            if metadata[\"count\"] < min_model_agreement:\n",
        "                continue\n",
        "\n",
        "            relevance_score = metadata[\"count\"]\n",
        "\n",
        "            disease_labels = {\n",
        "                'DISEASE', 'DISORDER', 'CONDITION', 'SYNDROME', 'CANCER',\n",
        "                'PATHOLOGICAL_FORMATION', 'INJURY_OR_POISONING'\n",
        "            }\n",
        "            if any(label in disease_labels for label in metadata[\"labels\"]):\n",
        "                relevance_score *= 2.0\n",
        "\n",
        "            treatment_labels = {\n",
        "                'CHEMICAL', 'DRUG', 'MEDICATION', 'THERAPEUTIC_PROCEDURE',\n",
        "                'SIMPLE_CHEMICAL', 'PHARMACOLOGIC_SUBSTANCE'\n",
        "            }\n",
        "            if any(label in treatment_labels for label in metadata[\"labels\"]):\n",
        "                relevance_score *= 1.5\n",
        "\n",
        "            genetic_labels = {'GENE', 'PROTEIN', 'GENE_OR_GENE_PRODUCT'}\n",
        "            if any(label in genetic_labels for label in metadata[\"labels\"]):\n",
        "                relevance_score *= 1.3\n",
        "\n",
        "            ranked_entities.append((text, relevance_score, metadata))\n",
        "\n",
        "        # Sort by relevance score\n",
        "        ranked_entities.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        if not ranked_entities:\n",
        "            return \"No medical entities found for PubMed query generation\"\n",
        "\n",
        "        query_parts = []\n",
        "        selected_entities = ranked_entities[:max_terms]\n",
        "\n",
        "        terms = []\n",
        "        for text, _, _ in selected_entities:\n",
        "            if ' ' in text:\n",
        "                terms.append(f'\"{text}\"')\n",
        "            else:\n",
        "                terms.append(text)\n",
        "\n",
        "        if terms:\n",
        "            query_parts.append(f\"({' OR '.join(terms)})\")\n",
        "\n",
        "        # Add context based on entity types\n",
        "        all_labels = set()\n",
        "        for _, _, metadata in selected_entities:\n",
        "            all_labels.update(metadata['labels'])\n",
        "\n",
        "        # Add appropriate search filters\n",
        "        if any(label in ['DISEASE', 'DISORDER', 'CONDITION'] for label in all_labels):\n",
        "            query_parts.append(\"(treatment OR therapy OR management OR guidelines)\")\n",
        "\n",
        "        if any(label in ['CHEMICAL', 'DRUG', 'MEDICATION'] for label in all_labels):\n",
        "            query_parts.append(\"(efficacy OR safety OR \\\"adverse effects\\\")\")\n",
        "\n",
        "        if any(label in ['GENE', 'PROTEIN'] for label in all_labels):\n",
        "            query_parts.append(\"(function OR mutation OR expression)\")\n",
        "\n",
        "        # Add publication type filters\n",
        "        query_parts.append(\"(\\\"Clinical Trial\\\" OR \\\"Systematic Review\\\" OR \\\"Meta-Analysis\\\")\")\n",
        "\n",
        "        return \" AND \".join(query_parts)\n",
        "\n",
        "    def get_medical_entity_summary(self) -> Dict[str, Any]:\n",
        "\n",
        "        summary = {\n",
        "            \"total_medical_entities\": 0,\n",
        "            \"unique_medical_entities\": set(),\n",
        "            \"diseases_conditions\": [],\n",
        "            \"chemicals_drugs\": [],\n",
        "            \"genes_proteins\": [],\n",
        "            \"anatomy\": [],\n",
        "            \"procedures\": [],\n",
        "            \"other_medical\": []\n",
        "        }\n",
        "\n",
        "        # Categorize entities by their labels\n",
        "        for model_data in self.results['models'].values():\n",
        "            if 'medical_entities' in model_data:\n",
        "                for entity in model_data['medical_entities']:\n",
        "                    summary['total_medical_entities'] += 1\n",
        "                    summary['unique_medical_entities'].add(entity['text'].lower())\n",
        "\n",
        "                    label = entity['label']\n",
        "                    text = entity['text']\n",
        "\n",
        "                    if label in ['DISEASE', 'DISORDER', 'CONDITION', 'SYNDROME',\n",
        "                               'CANCER', 'PATHOLOGICAL_FORMATION']:\n",
        "                        summary['diseases_conditions'].append(text)\n",
        "                    elif label in ['CHEMICAL', 'DRUG', 'MEDICATION', 'SIMPLE_CHEMICAL',\n",
        "                                 'PHARMACOLOGIC_SUBSTANCE', 'CHEBI']:\n",
        "                        summary['chemicals_drugs'].append(text)\n",
        "                    elif label in ['GENE', 'PROTEIN', 'GENE_OR_GENE_PRODUCT']:\n",
        "                        summary['genes_proteins'].append(text)\n",
        "                    elif label in ['ANATOMY', 'BODY_PART', 'ORGAN', 'TISSUE',\n",
        "                                 'MULTI_TISSUE_STRUCTURE']:\n",
        "                        summary['anatomy'].append(text)\n",
        "                    elif label in ['DIAGNOSTIC_PROCEDURE', 'THERAPEUTIC_PROCEDURE',\n",
        "                                 'LABORATORY_PROCEDURE']:\n",
        "                        summary['procedures'].append(text)\n",
        "                    else:\n",
        "                        summary['other_medical'].append(text)\n",
        "\n",
        "        summary['unique_medical_entities'] = len(summary['unique_medical_entities'])\n",
        "        for category in ['diseases_conditions', 'chemicals_drugs', 'genes_proteins',\n",
        "                        'anatomy', 'procedures', 'other_medical']:\n",
        "            summary[category] = list(set(summary[category]))\n",
        "\n",
        "        return summary\n",
        "\n",
        "    def export_results(self, filename: str = \"scispacy_medical_analysis.json\"):\n",
        "        with open(filename, 'w') as f:\n",
        "            json.dump(self.results, f, indent=2)\n",
        "        logger.info(f\"Results exported to {filename}\")\n",
        "\n",
        "    def get_entity_overlap_matrix(self, medical_only: bool = True) -> pd.DataFrame:\n",
        "\n",
        "        models = [m for m in self.results['models'] if 'entities' in self.results['models'][m]]\n",
        "        matrix = pd.DataFrame(index=models, columns=models, dtype=float)\n",
        "\n",
        "        entity_key = 'medical_entities' if medical_only else 'entities'\n",
        "\n",
        "        for i, model1 in enumerate(models):\n",
        "            entities1 = {e['text'].lower() for e in self.results['models'][model1].get(entity_key, [])}\n",
        "\n",
        "            for j, model2 in enumerate(models):\n",
        "                entities2 = {e['text'].lower() for e in self.results['models'][model2].get(entity_key, [])}\n",
        "\n",
        "                if len(entities1) > 0 or len(entities2) > 0:\n",
        "                    overlap = len(entities1.intersection(entities2))\n",
        "                    total = len(entities1.union(entities2))\n",
        "                    matrix.loc[model1, model2] = overlap / total if total > 0 else 0\n",
        "                else:\n",
        "                    matrix.loc[model1, model2] = 0\n",
        "\n",
        "        return matrix\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    sample_texts = [\n",
        "        \"\"\"The patient is a 72 year old white male who was transferred from Cay Memorial Hospital Of for cardiac catheterization and Electrophysiology Studies .\n",
        "His cardiac risk factors include :\n",
        "hypercholesterolemia , hypertension and insulin dependent diabetes mellitus .\n",
        "He has a history of chest pain and in January 1993 underwent a cardiac catheterization at Ph University Of Medical Center which revealed an occluded right coronary artery and a 40-50% proximal stenosis .\n",
        "He subsequently had an echocardiogram in December 1994 which showed normal left ventricular size and systolic function .\"\"\",\n",
        "\n",
        "        \"\"\"She had a liver function test and amylase and lipase postoperatively and she had a digoxin level of 1.0 on 06/04/05 .\n",
        "The patient had a CBC on admission of 14.1 with a hematocrit of 33.8 .\n",
        "Her CBC remained stable on 06/05/05 .\n",
        "She had a white blood cell of 7.7 , hematocrit of 30.6 .\n",
        "The patient had a MRSA nasal culture obtained on 06/03/05 , which revealed rare staphylococcus aureus .\n",
        "The patient had a chest x-ray on admission , which was clear .\n",
        "No pleural effusion or pneumothorax .\"\"\",\n",
        "\n",
        "        \"\"\"The patient is a 64-year-old male with a long standing history of peripheral vascular disease who has had multiple vascular procedures in the past including a fem-fem bypass , a left fem pop as well as bilateral TMAs and a right fem pop bypass who presents with a nonhealing wound of his left TMA stump as well as a pretibial ulcer that is down to the bone .\n",
        "The patient was admitted to obtain adequate pain control and to have an MRI / MRA to evaluate any possible bypass procedures that could be performed .\"\"\"\n",
        "    ]\n",
        "\n",
        "    expected_entities = [\n",
        "        [\"echocardiogram\", \"hypertension\", \"diabetes\", \"cardiac catheterization\", \"chest pain\", \"an occluded right coronary artery\", \"a 40-50% proximal stenosis\",\n",
        "         \"coronary artery\", \"cardiac catheterization\",\"electrophysiology studies\", \"hypercholesterolemia\", \"insulin dependent diabetes mellitus\"],\n",
        "\n",
        "        [\"a digoxin level\", \"cbc\", \"chest x-ray\", 'pleural effusion', 'liver function test', 'white blood cell', 'hematocrit', 'rare staphylococcus aureus',\n",
        "         'mrsa nasal culture', 'amylase', 'lipase', 'pneumothorax'],\n",
        "\n",
        "        [\"bilateral tmas\", \"peripheral vascular disease\", \"fem-fem bypass\", \"right fem pop bypass\",\n",
        "         \"left fem pop\", \"pain control\", \"vascular procedures\", 'mri', 'mra', 'non healing wound', 'tma stump', 'bypass procedures']\n",
        "    ]\n",
        "\n",
        "    # Initialize analyzer\n",
        "    analyzer = ScispaCyNERAnalyzer(min_entity_length=3)\n",
        "\n",
        "    print(\"Starting evaluation...\")\n",
        "    print(f\"Available models: {', '.join(analyzer.available_models)}\")\n",
        "\n",
        "    medical_models = [\n",
        "        \"en_ner_bc5cdr_md\",\n",
        "        \"en_ner_jnlpba_md\",\n",
        "        \"en_ner_bionlp13cg_md\",\n",
        "        \"en_core_sci_lg\",\n",
        "        \"en_core_sci_scibert\",\n",
        "         \"en_ner_craft_md\"\n",
        "    ]\n",
        "\n",
        "    # Filter to available models\n",
        "    selected_models = [m for m in medical_models if m in analyzer.available_models]\n",
        "\n",
        "    print(f\"\\nEvaluating models: {', '.join(selected_models)}\")\n",
        "\n",
        "    # Run evaluation\n",
        "    evaluation_results = analyzer.evaluate_models(\n",
        "        sample_texts=sample_texts,\n",
        "        expected_entities=expected_entities,\n",
        "        models=selected_models,\n",
        "        case_sensitive=False,\n",
        "        partial_match=False\n",
        "    )\n",
        "\n",
        "    # Generate evaluation report\n",
        "    eval_report = analyzer.generate_evaluation_report()\n",
        "    print(\"\\n\" + eval_report)\n",
        "\n",
        "    # Export evaluation results\n",
        "    analyzer.export_evaluation_results()\n",
        "\n",
        "    # Get error analysis\n",
        "    error_df = analyzer.get_error_analysis()\n",
        "    if not error_df.empty:\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"ERROR ANALYSIS\")\n",
        "        print(\"=\"*80)\n",
        "        print(error_df.to_string(index=False))\n",
        "\n",
        "    print(\"\\n\\nRunning regular analysis on sample text...\")\n",
        "    results = analyzer.analyze_text(sample_texts[0], models=selected_models)\n",
        "\n",
        "    # Get medical entity summary\n",
        "    summary = analyzer.get_medical_entity_summary()\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"MEDICAL ENTITY SUMMARY\")\n",
        "    print(\"=\"*80)\n",
        "    print(f\"Total medical entities: {summary['total_medical_entities']}\")\n",
        "    print(f\"Unique medical entities: {summary['unique_medical_entities']}\")\n",
        "\n",
        "    # Generate PubMed query\n",
        "    pubmed_query = analyzer.generate_pubmed_query(max_terms=5, min_model_agreement=1)\n",
        "    print(f\"\\nGenerated PubMed Query:\\n{pubmed_query}\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:✗ Model not available: en_core_sci_scibert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting evaluation...\n",
            "Available models: en_core_sci_lg, en_ner_bc5cdr_md, en_ner_jnlpba_md, en_ner_bionlp13cg_md, en_ner_craft_md\n",
            "\n",
            "Evaluating models: en_ner_bc5cdr_md, en_ner_jnlpba_md, en_ner_bionlp13cg_md, en_core_sci_lg, en_ner_craft_md\n",
            "\n",
            "================================================================================\n",
            "SCISPACY MODEL EVALUATION REPORT\n",
            "================================================================================\n",
            "\n",
            "Evaluation Date: 2025-07-04T07:27:21.013091\n",
            "Number of Samples: 3\n",
            "Case Sensitive: False\n",
            "Partial Match: False\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "MODEL PERFORMANCE SUMMARY\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "               Model  Status Precision Recall F1-Score\n",
            "    en_ner_bc5cdr_md Success     0.462  0.171    0.250\n",
            "    en_ner_jnlpba_md Success     0.400  0.057    0.100\n",
            "en_ner_bionlp13cg_md Success     0.250  0.171    0.203\n",
            "      en_core_sci_lg Success     0.000  0.000    0.000\n",
            "     en_ner_craft_md Success     0.000  0.000    0.000\n",
            "\n",
            "================================================================================\n",
            "DETAILED MODEL EVALUATION\n",
            "================================================================================\n",
            "\n",
            "\n",
            "============================================================\n",
            "Model: en_ner_bc5cdr_md\n",
            "============================================================\n",
            "\n",
            "Overall Performance:\n",
            "  Precision: 0.462\n",
            "  Recall: 0.171\n",
            "  F1-Score: 0.250\n",
            "  True Positives: 6\n",
            "  False Positives: 7\n",
            "  False Negatives: 29\n",
            "\n",
            "Average Sample Performance:\n",
            "  Avg Precision: 0.489\n",
            "  Avg Recall: 0.174\n",
            "  Avg F1-Score: 0.253\n",
            "\n",
            "Sample-Level Results (first 5):\n",
            "\n",
            "  Sample 0:\n",
            "    Text: The patient is a 72 year old white male who was transferred from Cay Memorial Hospital Of for cardia...\n",
            "    Expected: echocardiogram, hypertension, diabetes, cardiac catheterization, chest pain\n",
            "              ... and 7 more\n",
            "    Predicted: hypercholesterolemia, hypertension, diabetes mellitus, chest pain, proximal stenosis\n",
            "    Metrics: P=0.600, R=0.273, F1=0.375\n",
            "\n",
            "  Sample 1:\n",
            "    Text: She had a liver function test and amylase and lipase postoperatively and she had a digoxin level of ...\n",
            "    Expected: a digoxin level, cbc, chest x-ray, pleural effusion, liver function test\n",
            "              ... and 7 more\n",
            "    Predicted: digoxin, pleural effusion, pneumothorax\n",
            "    Metrics: P=0.667, R=0.167, F1=0.267\n",
            "\n",
            "  Sample 2:\n",
            "    Text: The patient is a 64-year-old male with a long standing history of peripheral vascular disease who ha...\n",
            "    Expected: bilateral tmas, peripheral vascular disease, fem-fem bypass, right fem pop bypass, left fem pop\n",
            "              ... and 7 more\n",
            "    Predicted: peripheral vascular disease, nonhealing, TMA, pretibial ulcer, pain\n",
            "    Metrics: P=0.200, R=0.083, F1=0.118\n",
            "\n",
            "\n",
            "============================================================\n",
            "Model: en_ner_jnlpba_md\n",
            "============================================================\n",
            "\n",
            "Overall Performance:\n",
            "  Precision: 0.400\n",
            "  Recall: 0.057\n",
            "  F1-Score: 0.100\n",
            "  True Positives: 2\n",
            "  False Positives: 3\n",
            "  False Negatives: 33\n",
            "\n",
            "Average Sample Performance:\n",
            "  Avg Precision: 0.500\n",
            "  Avg Recall: 0.056\n",
            "  Avg F1-Score: 0.099\n",
            "\n",
            "Sample-Level Results (first 5):\n",
            "\n",
            "  Sample 0:\n",
            "    Text: The patient is a 72 year old white male who was transferred from Cay Memorial Hospital Of for cardia...\n",
            "    Expected: echocardiogram, hypertension, diabetes, cardiac catheterization, chest pain\n",
            "              ... and 7 more\n",
            "    Predicted: His, insulin\n",
            "    Metrics: P=0.000, R=0.000, F1=0.000\n",
            "\n",
            "  Sample 1:\n",
            "    Text: She had a liver function test and amylase and lipase postoperatively and she had a digoxin level of ...\n",
            "    Expected: a digoxin level, cbc, chest x-ray, pleural effusion, liver function test\n",
            "              ... and 7 more\n",
            "    Predicted: amylase\n",
            "    Metrics: P=1.000, R=0.083, F1=0.154\n",
            "\n",
            "  Sample 2:\n",
            "    Text: The patient is a 64-year-old male with a long standing history of peripheral vascular disease who ha...\n",
            "    Expected: bilateral tmas, peripheral vascular disease, fem-fem bypass, right fem pop bypass, left fem pop\n",
            "              ... and 7 more\n",
            "    Predicted: right fem, MRA\n",
            "    Metrics: P=0.500, R=0.083, F1=0.143\n",
            "\n",
            "\n",
            "============================================================\n",
            "Model: en_ner_bionlp13cg_md\n",
            "============================================================\n",
            "\n",
            "Overall Performance:\n",
            "  Precision: 0.250\n",
            "  Recall: 0.171\n",
            "  F1-Score: 0.203\n",
            "  True Positives: 6\n",
            "  False Positives: 18\n",
            "  False Negatives: 29\n",
            "\n",
            "Average Sample Performance:\n",
            "  Avg Precision: 0.229\n",
            "  Avg Recall: 0.172\n",
            "  Avg F1-Score: 0.195\n",
            "\n",
            "Sample-Level Results (first 5):\n",
            "\n",
            "  Sample 0:\n",
            "    Text: The patient is a 72 year old white male who was transferred from Cay Memorial Hospital Of for cardia...\n",
            "    Expected: echocardiogram, hypertension, diabetes, cardiac catheterization, chest pain\n",
            "              ... and 7 more\n",
            "    Predicted: patient, cardiac catheterization, cardiac, insulin, cardiac catheterization\n",
            "               ... and 3 more\n",
            "    Metrics: P=0.286, R=0.182, F1=0.222\n",
            "\n",
            "  Sample 1:\n",
            "    Text: She had a liver function test and amylase and lipase postoperatively and she had a digoxin level of ...\n",
            "    Expected: a digoxin level, cbc, chest x-ray, pleural effusion, liver function test\n",
            "              ... and 7 more\n",
            "    Predicted: liver, amylase, lipase, digoxin, patient\n",
            "               ... and 8 more\n",
            "    Metrics: P=0.400, R=0.333, F1=0.364\n",
            "\n",
            "  Sample 2:\n",
            "    Text: The patient is a 64-year-old male with a long standing history of peripheral vascular disease who ha...\n",
            "    Expected: bilateral tmas, peripheral vascular disease, fem-fem bypass, right fem pop bypass, left fem pop\n",
            "              ... and 7 more\n",
            "    Predicted: patient, peripheral vascular, vascular, fem, fem\n",
            "               ... and 4 more\n",
            "    Metrics: P=0.000, R=0.000, F1=0.000\n",
            "\n",
            "\n",
            "============================================================\n",
            "Model: en_core_sci_lg\n",
            "============================================================\n",
            "\n",
            "Overall Performance:\n",
            "  Precision: 0.000\n",
            "  Recall: 0.000\n",
            "  F1-Score: 0.000\n",
            "  True Positives: 0\n",
            "  False Positives: 0\n",
            "  False Negatives: 35\n",
            "\n",
            "Average Sample Performance:\n",
            "  Avg Precision: 0.000\n",
            "  Avg Recall: 0.000\n",
            "  Avg F1-Score: 0.000\n",
            "\n",
            "Sample-Level Results (first 5):\n",
            "\n",
            "  Sample 0:\n",
            "    Text: The patient is a 72 year old white male who was transferred from Cay Memorial Hospital Of for cardia...\n",
            "    Expected: echocardiogram, hypertension, diabetes, cardiac catheterization, chest pain\n",
            "              ... and 7 more\n",
            "    Predicted: \n",
            "    Metrics: P=0.000, R=0.000, F1=0.000\n",
            "\n",
            "  Sample 1:\n",
            "    Text: She had a liver function test and amylase and lipase postoperatively and she had a digoxin level of ...\n",
            "    Expected: a digoxin level, cbc, chest x-ray, pleural effusion, liver function test\n",
            "              ... and 7 more\n",
            "    Predicted: \n",
            "    Metrics: P=0.000, R=0.000, F1=0.000\n",
            "\n",
            "  Sample 2:\n",
            "    Text: The patient is a 64-year-old male with a long standing history of peripheral vascular disease who ha...\n",
            "    Expected: bilateral tmas, peripheral vascular disease, fem-fem bypass, right fem pop bypass, left fem pop\n",
            "              ... and 7 more\n",
            "    Predicted: \n",
            "    Metrics: P=0.000, R=0.000, F1=0.000\n",
            "\n",
            "\n",
            "============================================================\n",
            "Model: en_ner_craft_md\n",
            "============================================================\n",
            "\n",
            "Overall Performance:\n",
            "  Precision: 0.000\n",
            "  Recall: 0.000\n",
            "  F1-Score: 0.000\n",
            "  True Positives: 0\n",
            "  False Positives: 2\n",
            "  False Negatives: 35\n",
            "\n",
            "Average Sample Performance:\n",
            "  Avg Precision: 0.000\n",
            "  Avg Recall: 0.000\n",
            "  Avg F1-Score: 0.000\n",
            "\n",
            "Sample-Level Results (first 5):\n",
            "\n",
            "  Sample 0:\n",
            "    Text: The patient is a 72 year old white male who was transferred from Cay Memorial Hospital Of for cardia...\n",
            "    Expected: echocardiogram, hypertension, diabetes, cardiac catheterization, chest pain\n",
            "              ... and 7 more\n",
            "    Predicted: His\n",
            "    Metrics: P=0.000, R=0.000, F1=0.000\n",
            "\n",
            "  Sample 1:\n",
            "    Text: She had a liver function test and amylase and lipase postoperatively and she had a digoxin level of ...\n",
            "    Expected: a digoxin level, cbc, chest x-ray, pleural effusion, liver function test\n",
            "              ... and 7 more\n",
            "    Predicted: blood cell\n",
            "    Metrics: P=0.000, R=0.000, F1=0.000\n",
            "\n",
            "  Sample 2:\n",
            "    Text: The patient is a 64-year-old male with a long standing history of peripheral vascular disease who ha...\n",
            "    Expected: bilateral tmas, peripheral vascular disease, fem-fem bypass, right fem pop bypass, left fem pop\n",
            "              ... and 7 more\n",
            "    Predicted: \n",
            "    Metrics: P=0.000, R=0.000, F1=0.000\n",
            "\n",
            "================================================================================\n",
            "BEST PERFORMING MODEL\n",
            "================================================================================\n",
            "\n",
            "Best Model: en_ner_bc5cdr_md\n",
            "F1-Score: 0.250\n",
            "\n",
            "================================================================================\n",
            "ERROR ANALYSIS\n",
            "================================================================================\n",
            "               Model     Error Type                              Entity  Count\n",
            "    en_ner_bc5cdr_md False Positive                   diabetes mellitus      1\n",
            "    en_ner_bc5cdr_md False Positive                   proximal stenosis      1\n",
            "    en_ner_bc5cdr_md False Positive                             digoxin      1\n",
            "    en_ner_bc5cdr_md False Positive                     pretibial ulcer      1\n",
            "    en_ner_bc5cdr_md False Positive                                pain      1\n",
            "    en_ner_bc5cdr_md False Positive                          nonhealing      1\n",
            "    en_ner_bc5cdr_md False Positive                                 TMA      1\n",
            "    en_ner_bc5cdr_md False Negative          a 40-50% proximal stenosis      1\n",
            "    en_ner_bc5cdr_md False Negative           electrophysiology studies      1\n",
            "    en_ner_bc5cdr_md False Negative                      echocardiogram      1\n",
            "    en_ner_bc5cdr_md False Negative                     coronary artery      1\n",
            "    en_ner_bc5cdr_md False Negative   an occluded right coronary artery      1\n",
            "    en_ner_bc5cdr_md False Negative                            diabetes      1\n",
            "    en_ner_bc5cdr_md False Negative insulin dependent diabetes mellitus      1\n",
            "    en_ner_bc5cdr_md False Negative             cardiac catheterization      1\n",
            "    en_ner_bc5cdr_md False Negative                                 cbc      1\n",
            "    en_ner_bc5cdr_md False Negative                  mrsa nasal culture      1\n",
            "    en_ner_jnlpba_md False Positive                                 His      1\n",
            "    en_ner_jnlpba_md False Positive                             insulin      1\n",
            "    en_ner_jnlpba_md False Positive                           right fem      1\n",
            "    en_ner_jnlpba_md False Positive                                 MRA      1\n",
            "    en_ner_jnlpba_md False Negative          a 40-50% proximal stenosis      1\n",
            "    en_ner_jnlpba_md False Negative                hypercholesterolemia      1\n",
            "    en_ner_jnlpba_md False Negative                        hypertension      1\n",
            "    en_ner_jnlpba_md False Negative           electrophysiology studies      1\n",
            "    en_ner_jnlpba_md False Negative                      echocardiogram      1\n",
            "    en_ner_jnlpba_md False Negative                          chest pain      1\n",
            "    en_ner_jnlpba_md False Negative                     coronary artery      1\n",
            "    en_ner_jnlpba_md False Negative   an occluded right coronary artery      1\n",
            "    en_ner_jnlpba_md False Negative                            diabetes      1\n",
            "    en_ner_jnlpba_md False Negative insulin dependent diabetes mellitus      1\n",
            "en_ner_bionlp13cg_md False Positive                             patient      3\n",
            "en_ner_bionlp13cg_md False Positive                             insulin      1\n",
            "en_ner_bionlp13cg_md False Positive                             cardiac      1\n",
            "en_ner_bionlp13cg_md False Positive                    left ventricular      1\n",
            "en_ner_bionlp13cg_md False Positive                            systolic      1\n",
            "en_ner_bionlp13cg_md False Positive                          blood cell      1\n",
            "en_ner_bionlp13cg_md False Positive                       nasal culture      1\n",
            "en_ner_bionlp13cg_md False Positive                             pleural      1\n",
            "en_ner_bionlp13cg_md False Positive                               liver      1\n",
            "en_ner_bionlp13cg_md False Positive                                 CBC      1\n",
            "en_ner_bionlp13cg_md False Negative          a 40-50% proximal stenosis      1\n",
            "en_ner_bionlp13cg_md False Negative                hypercholesterolemia      1\n",
            "en_ner_bionlp13cg_md False Negative                        hypertension      1\n",
            "en_ner_bionlp13cg_md False Negative           electrophysiology studies      1\n",
            "en_ner_bionlp13cg_md False Negative                      echocardiogram      1\n",
            "en_ner_bionlp13cg_md False Negative                          chest pain      1\n",
            "en_ner_bionlp13cg_md False Negative   an occluded right coronary artery      1\n",
            "en_ner_bionlp13cg_md False Negative                            diabetes      1\n",
            "en_ner_bionlp13cg_md False Negative insulin dependent diabetes mellitus      1\n",
            "en_ner_bionlp13cg_md False Negative                                 cbc      1\n",
            "      en_core_sci_lg False Negative          a 40-50% proximal stenosis      1\n",
            "      en_core_sci_lg False Negative                hypercholesterolemia      1\n",
            "      en_core_sci_lg False Negative                        hypertension      1\n",
            "      en_core_sci_lg False Negative           electrophysiology studies      1\n",
            "      en_core_sci_lg False Negative                      echocardiogram      1\n",
            "      en_core_sci_lg False Negative                          chest pain      1\n",
            "      en_core_sci_lg False Negative                     coronary artery      1\n",
            "      en_core_sci_lg False Negative   an occluded right coronary artery      1\n",
            "      en_core_sci_lg False Negative                            diabetes      1\n",
            "      en_core_sci_lg False Negative insulin dependent diabetes mellitus      1\n",
            "     en_ner_craft_md False Positive                                 His      1\n",
            "     en_ner_craft_md False Positive                          blood cell      1\n",
            "     en_ner_craft_md False Negative          a 40-50% proximal stenosis      1\n",
            "     en_ner_craft_md False Negative                hypercholesterolemia      1\n",
            "     en_ner_craft_md False Negative                        hypertension      1\n",
            "     en_ner_craft_md False Negative           electrophysiology studies      1\n",
            "     en_ner_craft_md False Negative                      echocardiogram      1\n",
            "     en_ner_craft_md False Negative                          chest pain      1\n",
            "     en_ner_craft_md False Negative                     coronary artery      1\n",
            "     en_ner_craft_md False Negative   an occluded right coronary artery      1\n",
            "     en_ner_craft_md False Negative                            diabetes      1\n",
            "     en_ner_craft_md False Negative insulin dependent diabetes mellitus      1\n",
            "\n",
            "\n",
            "Running regular analysis on sample text...\n",
            "\n",
            "================================================================================\n",
            "MEDICAL ENTITY SUMMARY\n",
            "================================================================================\n",
            "Total medical entities: 16\n",
            "Unique medical entities: 13\n",
            "\n",
            "Generated PubMed Query:\n",
            "(his OR insulin OR hypercholesterolemia OR hypertension OR \"diabetes mellitus\") AND (treatment OR therapy OR management OR guidelines) AND (function OR mutation OR expression) AND (\"Clinical Trial\" OR \"Systematic Review\" OR \"Meta-Analysis\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XTUuPB_sAPDG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}